{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-TRtwDNmOaDJ"
      },
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Metrics(model, X_test, y_test, class_names):\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Compute Accuracy and F1-score\n",
        "    acc = accuracy_score(y_true_classes, y_pred_classes)\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    print(f\"Test F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GFK-ib_NgPsw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Visualization(history):\n",
        "  # Plot Loss and Accuracy Curves\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Loss Plot\n",
        "    ax[0].plot(history.history['loss'], label='Train Loss')\n",
        "    ax[0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax[0].set_title('Loss Curve')\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].legend()\n",
        "\n",
        "    # Accuracy Plot\n",
        "    ax[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax[1].set_title('Accuracy Curve')\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "    ax[1].set_ylabel('Accuracy')\n",
        "    ax[1].legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lwCmpMKinWuE"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}